# PMM Environment Configuration Template
# Copy this file to .env and fill in your actual values

# ============================================================================
# LLM Provider Configuration
# ============================================================================

# OpenAI Configuration (for gpt-4, gpt-3.5-turbo, etc.)
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_BASE_URL=https://api.openai.com

# Ollama Configuration (for local and cloud models)
# For local Ollama: leave OLLAMA_API_KEY empty
# For Ollama Cloud: get API key from Ollama Cloud dashboard
OLLAMA_API_KEY=your-ollama-cloud-api-key-here
OLLAMA_BASE_URL=http://localhost:11434

# ============================================================================
# PMM Core Configuration
# ============================================================================

# Default model selection
PMM_PROVIDER=ollama
PMM_MODEL=llama3.2:1b
PMM_DEFAULT_MODEL=llama3
PMM_DEFAULT_BASE_URL=http://localhost:11434

# Database path
PMM_DB=.data/pmm.db
PMM_DB_PATH=.data/pmm.db

# ============================================================================
# Advanced Configuration (Optional)
# ============================================================================

# N-gram filter for content filtering
PMM_NGRAM_BAN_FILE=

# Model selection preferences
OPENAI_MODEL=gpt-4o-mini

# ============================================================================
# Security Notes
# ============================================================================
# 
# 1. NEVER commit .env files to git (already in .gitignore)
# 2. Keep API keys secure and rotate them regularly
# 3. Use different keys for development vs production
# 4. For Ollama Cloud models like gpt-oss:120b-cloud, you need OLLAMA_API_KEY
# 5. For local Ollama models, OLLAMA_API_KEY can be empty/unset
